{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok\n",
        "!pip install markdown2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NeFb0XESaeE",
        "outputId": "e931ba7c-345e-459e-f9c5-c61f3a6fa97a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.10/dist-packages (2.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import os                                                                       #Imports OS to get a way to use operating system\n",
        "from flask import Flask, request, render_template, redirect, url_for, jsonify   #Imports various functions to work with flask\n",
        "from werkzeug.utils import secure_filename                                      #Enhances the security of the uploaded file\n",
        "from pyngrok import ngrok                                                       #Imports the ngrok to manage the tunnel\n",
        "authtoken = '2oQ7s6Vm4wdy0Mu0Cp7zXYqS27W_4wSAJru6wAmHBY5ebc7w8'                 #Takes the authorized token from the ngrok (User specific)\n",
        "ngrok.set_auth_token(authtoken)                                                 #Authorizes the ngrok tunnel with the help of the token\n",
        "import markdown2\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"infly/OpenCoder-1.5B-Instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# Set the computation device\n",
        "computation = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(computation)"
      ],
      "metadata": {
        "id": "KVm72VE5g_Gg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "def ensure_code_blocks(response):\n",
        "    # Fix any improperly formatted code blocks\n",
        "    response = re.sub(r\"(?<!```)```(\\w+)?\\n\", \"```\\n\", response)\n",
        "\n",
        "    # Wrap code snippets (inside triple backticks) in <pre class='code-block'>\n",
        "    response = re.sub(r\"```(.*?)```\", r\"<pre class='code-block'>\\1</pre>\", response, flags=re.DOTALL)\n",
        "\n",
        "    return response\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"\"\"\n",
        "    <h1>OpenCoder Model Interface</h1>\n",
        "    <form action=\"/generate\" method=\"post\">\n",
        "        <label for=\"question\">Enter your question:</label><br><br>\n",
        "        <textarea name=\"question\" rows=\"5\" cols=\"50\"></textarea><br><br>\n",
        "        <input type=\"submit\" value=\"Generate\">\n",
        "    </form>\n",
        "    \"\"\"\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    # Get the user input\n",
        "    user_input = request.form['question']\n",
        "\n",
        "    # Prepare the input for the model\n",
        "    messages = [{'role': 'user', 'content': user_input}]\n",
        "    inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(computation)\n",
        "\n",
        "\n",
        "    outputs = model.generate(inputs, max_new_tokens=512, do_sample=False)\n",
        "\n",
        "    # Generate the output\n",
        "    outputs = model.generate(inputs, max_new_tokens=512, do_sample=False)\n",
        "    result = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)\n",
        "\n",
        "    formatted_response = ensure_code_blocks(result)\n",
        "\n",
        "        # Convert the formatted response to HTML\n",
        "    final_response = markdown2.markdown(formatted_response)\n",
        "\n",
        "\n",
        "    # Return the result\n",
        "    return f\"<h1>Model Output:</h1><p>{final_response}</p><br><a href='/'>Go Back</a>\""
      ],
      "metadata": {
        "id": "cZAYv0DOQsy7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f'Public URL: {public_url}')\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb8Yn9sSQu0W",
        "outputId": "8fd2c247-fb3c-4172-c716-c84a0abcc97d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://09d2-34-168-57-6.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:07:25] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:07:26] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:08:14] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:08:29] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:08:39] \"GET / HTTP/1.1\" 200 -\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:09:36] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:09:44] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:10:05] \"GET / HTTP/1.1\" 200 -\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:10:24] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:10:31] \"GET / HTTP/1.1\" 200 -\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:11:11] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:11:17] \"GET / HTTP/1.1\" 200 -\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:11:47] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [22/Nov/2024 10:11:52] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xbl92tXsSDgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}